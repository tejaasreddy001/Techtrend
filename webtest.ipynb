{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import hashlib\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "headers = {\n",
        "    \"user-agent\": \"Chrome/91.0.4472.101\"\n",
        "}\n",
        "\n",
        "job2_list = ['Java-Developer','Testing','DevOps-Engineer','Python-Developer','Web-Designing','HR','Hadoop','Blockchain','ETL-Developer','Operations-Manager','Data-Science','Sales','Mechanical-Engineer',\n",
        " 'Arts','Database','Electrical-Engineering','Health-and-fitness','PMO','Business-Analyst','DotNet-Developer','Automation-Testing','Network-Security-Engineer','SAP-Developer','Civil-Engineer','Advocate']\n",
        "\n",
        "job_list = ['Java Developer','Testing','DevOps Engineer','Python Developer','Web Designing','HR','Hadoop','Blockchain','ETL Developer','Operations Manager','Data Science','Sales','Mechanical Engineer',\n",
        "'Arts','Database','Electrical Engineering','Health and fitness','PMO','Business Analyst','DotNet Developer','Automation Testing','Network Security Engineer','SAP Developer','Civil Engineer','Advocate']\n",
        "resume_links = pd.DataFrame()\n",
        "category = []\n",
        "link = []\n",
        "for i in range(0,len(job2_list)):\n",
        "  job = job2_list[i]\n",
        "  JOB2 = job_list[i]\n",
        "  JOB = job.lower()\n",
        "  print(JOB)\n",
        "  for i in range(1,4):\n",
        "    PAGE = str(i)\n",
        "    URL = \"https://www.livecareer.com/resume-search/search?jt=\"+ JOB + \"&bg=85&eg=100&comp=&mod=&pg=\"+ PAGE\n",
        "    page = requests.get(URL, headers=headers, timeout=20).content\n",
        "    soup = BeautifulSoup(page, \"html.parser\")\n",
        "    prettified_html = soup.prettify()\n",
        "    a_tags = soup.find_all('a', class_='sc-1dzblrg-0')\n",
        "    for a_tag in a_tags:\n",
        "      href_value = a_tag.get('href')\n",
        "      category.append(JOB2)\n",
        "      link.append(href_value)\n",
        "\n",
        "resume_links[\"Category\"] = category\n",
        "resume_links[\"link\"] = link\n",
        "\n",
        "def extract_next_div_text_after(html_content, section_title):\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    start_section = soup.find('div', class_='sectiontitle', string=lambda text: section_title in text)\n",
        "    text_content = \"\"\n",
        "    if start_section:\n",
        "        next_div = start_section.find_next('div')\n",
        "        if next_div:\n",
        "            text_content = next_div.get_text(separator='\\n', strip=True)\n",
        "    start_section = soup.find('div', class_='sectiontitle', string=lambda text: \"Experience\" in text)\n",
        "    if start_section:\n",
        "        next_div = start_section.find_next('div')\n",
        "\n",
        "        if next_div:\n",
        "            text_content = text_content + next_div.get_text(separator='\\n', strip=True)\n",
        "\n",
        "    return text_content if len(text_content) > 0 else None\n",
        "\n",
        "headers = {\n",
        "    \"user-agent\": \"Chrome/91.0.4472.101\"\n",
        "}\n",
        "\n",
        "resume_links[\"Resume\"] = \"\"\n",
        "\n",
        "print(resume_links.head())\n",
        "\n",
        "for i in range(resume_links.shape[0]):\n",
        "    url = 'https://www.livecareer.com' + resume_links.link[i]\n",
        "    page = requests.get(url, headers=headers, timeout=10).content\n",
        "    section_title = \"Skills\"\n",
        "    div = extract_next_div_text_after(page, section_title)\n",
        "    if div:\n",
        "      resume_links.Resume[i] = div"
      ],
      "metadata": {
        "id": "7J6P-v6mvu-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_links = resume_links.drop(columns=['link'])\n",
        "resume_links = resume_links[resume_links['Resume'].notna() & (resume_links['Resume'] != '')]\n",
        "resume_links.to_csv('/content/drive/MyDrive/updated_resume_data.csv', index=False)"
      ],
      "metadata": {
        "id": "vTDTrUA0IZ1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}